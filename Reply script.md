# Reply script

> 小组成员当中，周新梅同学因为新冠阳性发烧几天了，昨天晚上还烧到39.7，导致无法参加答辩	
>
> 我们的云存储服务平台从始至终全均由我们四人开发而成

## 使用的技术

我们使用了hdfs进行文件存储

hbase进行文件信息管理

mysql进行用户数据管理

Vue+ElementUI进行前端开发                                                                                                                                                                                                                                                                                                                                                                              

Django进行后端开发

> 为什么使用这些技术：
>
> hbase：作为云存储系统，文件及其相关数据量较大，且会并发产生的海量的数据处理，HBase分布式存储及集群中多节点并行查询操作的高性能很适合这个应用场景
>
> mysql：mysql有体积小，速度快，成本低的特点，在云存储平台当中，用户数据量及写操作规模较小，我们认为使用其来操作更为合适
>
> Vue+ElementUI：方便好用性能强
>
> django：由python编写开发较为快捷，使用代码量较小

## 整个项目的工作

在整个项目当中，我们制作了登录注册，信息展示，文件上传，下载，删除，搜索，分享这些功能，接下来我们给老师展示一下吧                

## 之前部署的服务与后来开发时的服务

在放假之前，我们将我们的服务器部署在校内的固定主机，但在离校后我们只能在家中开发，只能在每个人的电脑上配置相关环境，打包docker在家快捷部署，但是因为不同环境下，我们开发出现了很多问题和困难，在这种条件下，我们最后所有的环境都能正常运行进行完整调试的只有一个人

## 开发中遇到的问题

首先是开发hdfs，我们可以连接到hdfs，可以查看文件系统，但是没办法进行任何io操作，通过查找底层调用我们了解到它是调用webhdfs，并在其java调用的日志报错当中找到了其是不能解析host，然后修改docker的网络模式，也还是不行，在消耗了大量时间精力后，因为python后端及大部分框架已经完工，我们只能双线程解决问题，单子奇用java制作了hdfs和hbase操作，并确认了在java_api开放的9000端口上可以进行操作，我制作了python内嵌jpype的代码，在做完了这些的同时，我们也通过之前查到的webhdfs这个东西，查它的官方文档，访问14000端口，开启docker中的对应服务，修改hdfs及通信模块权限，实现了python的hdfs操作

对于开发hbase，该部分因为wsl最新更新出现的限制，其在操作hbase时会被拒绝，且无法解决，所以麦炜樑只能写相关函数，没办法进行实机调试，在该部分开发中，修改配置文件，配置thrift环境的常规操作后主要问题就是hbase中各个函数的设计和使用出现偏差，因为该部分函数的使用没有可靠的文档参考，且要实现我们希望的功能需要用到很多偏门的函数，比如模糊查找，这里我们就用到了两个很少用的函数，且在包中查看其参数和返回值，我们没办法确定类型，这些导致我们只能实机测试来做，最终因为参数和返回值类型不定，导致我们修改了很大一部分的相关参数，包括上传逻辑中行键的命名，根目录的修改以及前端发送数据规范的改变

## 这次实验对问题的总结

总的来说就是，在实际开发中，会遇到各种各样的问题，端与端之间的对接是最麻烦也是最多问题的，hadoop系列支持各种语言实际上是有些不准确的，python后端对大量调用了java函数，且只能使用web端来操作hdfs和hbase，这就导致了使用docker部署环境时，镜像环境和docker网络模式中存在大量的隐患，也体现出hdfs对host的高度依赖性，而在实验中，我们也的的确确没有办法模拟仿真我们应用的业务场景，

## 之后想要做的事

作为一个云存储平台，用户上传的数据量大且多，其中用户上传的数据对会使得文件存储有较大的压力，而这其中最大部分的就是用户之间彼此传播的文件，即分享功能，所以，在用户A分享时，用户B接收分享后应该只在hbase中添加一个文件信息，而该文件信息中应该有一个叫引用路径，所以hdfs就不会被大量因分享而创建的子文件拥挤了。当用户B想下载时，直接访问用户A的下载目录，删除时删除用户B中Hbase的信息。当用户A删除自己创建的子文件时，删除用户A中HBase的信息







​                                                                         

